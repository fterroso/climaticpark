{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BooWVfJkNRfs",
    "outputId": "461d7b73-52f7-48c4-f3d0-26ca621a4459"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries (see configuration file climaticpark_env.yml in github repo)\n",
    "#!pip install pybdshadow contextily folium pillow timezonefinder plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gw2SxXJJNyhf"
   },
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime as dt \n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "from enum import Enum\n",
    "import pytz\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "\n",
    "import branca\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "\n",
    "from IPython.core.display import display\n",
    "from IPython.display import IFrame\n",
    "\n",
    "from suncalc import get_position\n",
    "from pyproj import CRS,Transformer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShadowModule:\n",
    "        \n",
    "    def __init__(self, roofs:gpd.GeoDataFrame, spaces:gpd.GeoDataFrame):\n",
    "        self.roofs = roofs\n",
    "        self.spaces= spaces\n",
    "    \n",
    "    \n",
    "    def compute_coverage_rates(self, days_lst:list):\n",
    "        \"\"\"\n",
    "        Compute coverage rates for each day in days_lst\n",
    "        \"\"\"\n",
    "        coverage_rates_gdf = self.spaces.copy()# gpd.GeoDataFrame(geometry=self.spaces.geometry)\n",
    "        coverage_rates_gdf = coverage_rates_gdf.set_crs(epsg=4326)\n",
    "        \n",
    "        local_tz = pytz.timezone('Europe/Madrid')\n",
    "\n",
    "        shadows_lst = []\n",
    "        for current_date in days_lst:\n",
    "            # Compute shadow projections for roofs\n",
    "            for hour in range(0,24):\n",
    "                \n",
    "                date_hour = dt.combine(current_date, datetime.time(hour, 0)) \n",
    "                date_hour = local_tz.localize(date_hour)  # Localizarlo en la zona horaria de Madrid\n",
    "\n",
    "                coverage_rates= []\n",
    "                try:\n",
    "                    shadows_gdf = self._all_sunshadeshadow_sunlight(date_hour)\n",
    "                    shadows_lst.append((date_hour, shadows_gdf))\n",
    "                    \n",
    "\n",
    "                    # Calculate coverage rates\n",
    "                    intersection= coverage_rates_gdf.overlay(shadows_gdf, how='intersection')\n",
    "\n",
    "                    \n",
    "                    for index, parking_space in coverage_rates_gdf.iterrows():\n",
    "                        space_total_area = parking_space.geometry.area\n",
    "                        space_id = parking_space.space_id\n",
    "                        space_shadow_area_lst= intersection.loc[intersection['space_id']==space_id, \"geometry\"]\n",
    "                        space_shadow_area = space_shadow_area_lst.iloc[0].area if not space_shadow_area_lst.empty else 0\n",
    "                        #space_shadow_area = intersection.loc[index, \"geometry\"].area if index in intersection.index else 0 #intersection.loc[index,\"geometry\"].area\n",
    "                        space_coverage= space_shadow_area / space_total_area\n",
    "                        coverage_rates.append(space_coverage)\n",
    "                except Exception as e:\n",
    "                    coverage_rates = [0] * len(coverage_rates_gdf)\n",
    "                    print(f\"WARN:: No coverage computed for date {date_hour}: {e}\")\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "                coverage_rates = []\n",
    "                for index, parking_space in self.spaces.iterrows():\n",
    "                    parking_space_gdf = gpd.GeoDataFrame(geometry=self..geometry)\n",
    "                    parking_space_gdf = parking_space_gdf.set_crs(epsg=4326)\n",
    "                    parking_space_gdf = parking_space_gdf.to_crs(epsg=shadows_gdf.crs.to_epsg())\n",
    "\n",
    "                    intersection = gpd.overlay(parking_space_gdf, shadows_gdf, how='intersection')\n",
    "\n",
    "                    intersection_area = intersection.geometry.area.sum()\n",
    "                    parking_space_area = parking_space_gdf.geometry.area.sum()\n",
    "\n",
    "                    coverage_rate = intersection_area / parking_space_area\n",
    "                    coverage_rates.append(coverage_rate)\n",
    "                \"\"\"\n",
    "\n",
    "                coverage_rates_gdf[f'coverage_rate_{date_hour.strftime(\"%Y-%m-%d %H:%M\")}'] = coverage_rates\n",
    "\n",
    "        self._coverage_rates = coverage_rates_gdf\n",
    "        self._shadows_lst = shadows_lst\n",
    "        coverage_rates_gdf.to_file(\"test.geojson\", driver=\"GeoJSON\")\n",
    "        return coverage_rates_gdf\n",
    "\n",
    "    def show_coverage_rate_map(self):\n",
    "        # Extraer las columnas de tiempo (asegurarse de que están ordenadas)\n",
    "        coverage_cols = [col for col in self._coverage_rates.columns if \"coverage_rate_\" in col]\n",
    "        coverage_cols.sort()\n",
    "\n",
    "        # Crear el mapa base centrado en el área de los polígonos\n",
    "        m = folium.Map(\n",
    "            location=[self._coverage_rates.geometry.centroid.y.mean(), self._coverage_rates.geometry.centroid.x.mean()],\n",
    "            zoom_start=16,\n",
    "            max_zoom= 19,\n",
    "            tiles=\"cartodb positron\"\n",
    "        )\n",
    "\n",
    "        # Crear una paleta de colores basada en los valores de cobertura YlOrRd_09\n",
    "        colormap = branca.colormap.linear.Greys_09.scale(\n",
    "            self._coverage_rates[coverage_cols].min().min(), self._coverage_rates[coverage_cols].max().max()\n",
    "        )\n",
    "        colormap.caption = \"Coverage Rate\"\n",
    "        colormap.add_to(m)\n",
    "\n",
    "        # Crear una estructura para `TimestampedGeoJson`\n",
    "        features = []\n",
    "\n",
    "        for index, row in self._coverage_rates.iterrows():\n",
    "            for time_index, col in enumerate(coverage_cols):\n",
    "                feature = {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": mapping(row.geometry),  # Convertir a JSON\n",
    "                    \"properties\": {\n",
    "                        \"time\": col.replace(\"coverage_rate_\", \"\"),  # Extraer la fecha y hora\n",
    "                        \"style\": {\n",
    "                            \"fillColor\": colormap(row[col]),  # Color según la cobertura\n",
    "                            \"color\": \"black\",\n",
    "                            \"weight\": 0.5,\n",
    "                            \"fillOpacity\": 0.7,\n",
    "                        },\n",
    "                        \"popup\": f\"Coverage: {row[col]:.2f}\"\n",
    "                    }\n",
    "                }\n",
    "                features.append(feature)\n",
    "        # Crear un `TimestampedGeoJson`\n",
    "        TimestampedGeoJson(\n",
    "            {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": features,\n",
    "            },\n",
    "            period=\"PT1H\",  # Intervalo de tiempo (1 hora)\n",
    "            duration= \"PT1H\",\n",
    "            add_last_point=False,\n",
    "            auto_play=False,\n",
    "            loop=True,\n",
    "            max_speed=1,\n",
    "            loop_button=True,\n",
    "            date_options=\"YYYY-MM-DD HH:mm\",\n",
    "        ).add_to(m)\n",
    "        \n",
    "        folium.LayerControl().add_to(m)\n",
    "\n",
    "        # Guardar el mapa como HTML\n",
    "        m.save(\".climaticpark_coverage_rate_map.html\")\n",
    "\n",
    "        return m\n",
    "\n",
    "    def show_shadow_map(self):\n",
    "\n",
    "        # Customization\n",
    "        bordersStyle = {\n",
    "            'color': 'green',\n",
    "            'weight': 0.5,\n",
    "            'fillColor': 'blue',\n",
    "            'fillOpacity': 0.4\n",
    "        }\n",
    "\n",
    "        # Crear el mapa base centrado en el área de los polígonos\n",
    "        m = folium.Map(\n",
    "            location=[self.spaces.geometry.centroid.y.mean(), self.spaces.geometry.centroid.x.mean()],\n",
    "            zoom_start=16,\n",
    "            max_zoom= 19,\n",
    "            tiles=\"cartodb positron\"\n",
    "        )\n",
    "\n",
    "        folium.GeoJson(self.spaces, name='Spaces', style_function=lambda x: bordersStyle).add_to(m)\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for date, row in self._shadows_lst:\n",
    "            for g in row.geometry:\n",
    "                feature = {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": mapping(g),  # Convertir a JSON\n",
    "                    \"properties\": {\n",
    "                        \"time\": date.strftime(\"%Y-%m-%d %H:%M\"),  \n",
    "                        \"style\": {\n",
    "                            \"fillColor\": 'grey',  \n",
    "                            \"color\": \"black\",\n",
    "                            \"weight\": 0.5,\n",
    "                            \"fillOpacity\": 0.6,\n",
    "                        },\n",
    "                        \"popup\": \"shadow\"\n",
    "                    }\n",
    "                }\n",
    "                features.append(feature)\n",
    "\n",
    "        # Crear un `TimestampedGeoJson`\n",
    "        TimestampedGeoJson(\n",
    "            {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": features,\n",
    "            },\n",
    "            period=\"PT1H\",  # Intervalo de tiempo (1 hora)\n",
    "            duration=\"PT1M\",\n",
    "            add_last_point=False,\n",
    "            auto_play=False,\n",
    "            loop=True,\n",
    "            max_speed=1,\n",
    "            loop_button=True,\n",
    "            date_options=\"YYYY-MM-DD HH:mm\",\n",
    "        ).add_to(m)\n",
    "\n",
    "        m.save(\".climaticpark_roof_shadows_map.html\")\n",
    "\n",
    "        return m\n",
    "\n",
    "        # Define function to calculate shadow and sunlight for all rooftops\n",
    "    def _all_sunshadeshadow_sunlight(self, date:datetime.datetime):\n",
    "        roof_projected_df= self.roofs.copy()\n",
    "        roof_projected_df['geometry'] = roof_projected_df.apply(lambda r: self._sunshadeshadow_sunlight(date, r[0]), axis=1)\n",
    "\n",
    "        return roof_projected_df\n",
    "\n",
    "\n",
    "    def _sunshadeshadow_sunlight(self, date:datetime.datetime, r:Polygon, sunshade_height=2):\n",
    "        meanlon= r.centroid.y\n",
    "        meanlat= r.centroid.x\n",
    "        # obtain sun position\n",
    "        sunPosition = get_position(date, meanlon, meanlat)\n",
    "        if sunPosition['altitude'] < 0:\n",
    "            raise ValueError(\"Given time before sunrise or after sunset\")\n",
    "            \n",
    "        r_coords= np.array(r.exterior.coords)\n",
    "        r_coords= r_coords.reshape(1,-1,2)\n",
    "        shape = ShadowModule.lonlat2aeqd(r_coords,meanlon,meanlat)\n",
    "        azimuth = sunPosition['azimuth']\n",
    "        altitude = sunPosition['altitude']\n",
    "\n",
    "        n = np.shape(shape)[0]\n",
    "        distance = sunshade_height / math.tan(altitude)\n",
    "\n",
    "        # calculate the offset of the projection position\n",
    "        lonDistance = distance * math.sin(azimuth)\n",
    "        latDistance = distance * math.cos(azimuth)\n",
    "\n",
    "        shadowShape = np.zeros((1, 5, 2))\n",
    "        shadowShape[:, :, :] += shape\n",
    "        shadowShape[:, :, 0] = shape[:, :, 0] + lonDistance\n",
    "        shadowShape[:, :, 1] = shape[:, :, 1] + latDistance\n",
    "        shadowShape = ShadowModule.aeqd2lonlat(shadowShape,meanlon,meanlat)\n",
    "        p = Polygon([[p[0], p[1]] for p in shadowShape[0]])\n",
    "        return p\n",
    "    \n",
    "    @staticmethod\n",
    "    def lonlat2aeqd(lonlat:np.ndarray, center_lon:float, center_lat:float):\n",
    "        epsg = CRS.from_proj4(\"+proj=aeqd +lat_0=\"+str(center_lat) +\n",
    "                            \" +lon_0=\"+str(center_lon)+\" +datum=WGS84\")\n",
    "        transformer = Transformer.from_crs(\"EPSG:4326\", epsg, always_xy=True)\n",
    "        proj_coords = transformer.transform(lonlat[:, :, 0], lonlat[:, :, 1])\n",
    "        proj_coords = np.array(proj_coords).transpose([1, 2, 0])\n",
    "        return proj_coords\n",
    "    \n",
    "    @staticmethod\n",
    "    def aeqd2lonlat(proj_coords:np.ndarray, meanlon:float, meanlat:float):\n",
    "        epsg = CRS.from_proj4(\"+proj=aeqd +lat_0=\"+str(meanlat)+\" +lon_0=\"+str(meanlon)+\" +datum=WGS84\")\n",
    "        transformer = Transformer.from_crs( epsg,\"EPSG:4326\",always_xy = True)\n",
    "        lonlat = transformer.transform(proj_coords[:,:,0], proj_coords[:,:,1])\n",
    "        lonlat = np.array(lonlat).transpose([1,2,0])\n",
    "        return lonlat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemandModule:\n",
    "    def __init__(self, entry_exit_tuples:pd.DataFrame):        \n",
    "        self._entry_exit_tuples= entry_exit_tuples\n",
    "\n",
    "    def train_demand_predictors(self, lr=0.9, sequence_length= 12, show_details=True, refresh_model=False):\n",
    "        self._sequence_length= sequence_length\n",
    "\n",
    "        self._gmm_models={}\n",
    "        for hour, group in self._entry_exit_tuples.groupby('enter_hour'):\n",
    "            X = group[\"exit_hour\"].values  # Extraer los datos de las características para este grupo\n",
    "            if X.shape[0]== 1:\n",
    "                X= X.reshape(1, -1)\n",
    "            else:\n",
    "                X= X.reshape(-1,1)\n",
    "            if X.shape[0]>=2:\n",
    "                # Crear y ajustar el modelo GMM; ajusta n_components según tus necesidades\n",
    "                gmm = GaussianMixture(n_components=1, random_state=42)\n",
    "                gmm.fit(X)\n",
    "                self._gmm_models[hour] = gmm\n",
    "\n",
    "        model_path = os.path.join('_models', 'demand_cnnlstm_model.keras')\n",
    "        # Cargamos o entrenamos el modelo\n",
    "\n",
    "        n_incoming_veh_df= self._entry_exit_tuples.groupby('date').size().reset_index()\n",
    "        n_incoming_veh_df['datetime'] = pd.to_datetime(n_incoming_veh_df['date'])\n",
    "\n",
    "        # Establecer 'datetime' como índice\n",
    "        n_incoming_veh_df.set_index('datetime', inplace=True)\n",
    "\n",
    "        # Renombrar la columna 'num_vehicles'\n",
    "        n_incoming_veh_df.rename(columns={0: \"num_vehicles\"}, inplace=True)\n",
    "\n",
    "        # Eliminar columnas originales si ya no se necesitan\n",
    "        n_incoming_veh_df.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "        self._scaler = MinMaxScaler()\n",
    "        n_incoming_veh_df['num_vehicles'] = self._scaler.fit_transform(n_incoming_veh_df[['num_vehicles']])\n",
    "\n",
    "        values = n_incoming_veh_df['num_vehicles'].values\n",
    "        X, y = self._create_unidimensional_sequences(values, self._sequence_length)\n",
    "\n",
    "        # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-lr, random_state=42)\n",
    "\n",
    "        # Cambiar la forma de los datos para adaptarse a la entrada CNN-LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "        self._last_sequence = X_test[-1].flatten() \n",
    "\n",
    "        if os.path.exists(model_path) and not refresh_model:\n",
    "            print(f\"\\n\\tLoading demand predictor from {model_path}...\", end=\"\")\n",
    "            self._model = load_model(model_path)\n",
    "        else: \n",
    "            print(f\"\\n\\tTraining demand predictor...\", end=\"\")\n",
    "\n",
    "            # Definir el modelo CNN-LSTM\n",
    "            self._model = Sequential([\n",
    "                Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "                MaxPooling1D(pool_size=2),\n",
    "                LSTM(50, activation='relu', return_sequences=False),\n",
    "                Dense(1)\n",
    "            ])\n",
    "\n",
    "            self._model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            _verbose= 0\n",
    "            if show_details:\n",
    "                _verbose= 1\n",
    "            # Configuración de EarlyStopping\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\",  # Métrica que se monitorea\n",
    "                patience=10,         # Número de épocas de espera sin mejoras antes de detener\n",
    "                restore_best_weights=True,  # Restaurar los mejores pesos\n",
    "                verbose=_verbose          # Mostrar mensajes\n",
    "            )\n",
    "\n",
    "            # Entrenamiento con EarlyStopping\n",
    "            self._model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                epochs=1000,\n",
    "                batch_size=16,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[early_stopping],  # Incluir el callback\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            self._model.save(model_path)\n",
    "\n",
    "        print(\"DONE!\")\n",
    "\n",
    "    # Crear los datos de entrada y salida para la serie temporal\n",
    "    def _create_unidimensional_sequences(self, data, sequence_length:int):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:i + sequence_length])\n",
    "            y.append(data[i + sequence_length])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def _predict_occupancy(self, n_days_ahead:int):\n",
    "\n",
    "        future_predictions = []\n",
    "        current_sequence = self._last_sequence.copy()\n",
    "\n",
    "        for _ in range(n_days_ahead*24):\n",
    "            # Redimensionar la secuencia actual para que sea compatible con el modelo\n",
    "            input_data = np.array(current_sequence).reshape((1, self._sequence_length, 1))\n",
    "            \n",
    "            # Predecir el siguiente valor\n",
    "            next_pred = self._model.predict(input_data, verbose=0)[0][0]\n",
    "            \n",
    "            # Guardar el valor predicho (desnormalizado)\n",
    "            future_predictions.append(self._scaler.inverse_transform([[next_pred]])[0][0])\n",
    "\n",
    "            # Actualizar la secuencia de entrada con la nueva predicción\n",
    "            current_sequence = np.append(current_sequence[1:], next_pred)\n",
    "\n",
    "        return future_predictions\n",
    "\n",
    "    \"\"\"\n",
    "    def _generate_entry_and_exit_hours(self, n_tuples:int):\n",
    "        new_samples, _ = gm.sample(n_samples=n_tuples)\n",
    "        return [[math.floor(x[0]),math.floor(x[1])] for x in new_samples]\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_entry_exit_hours(self, date_lst:list):\n",
    "        \"\"\"\n",
    "        Simulates vehicle parking occupancy and generates a table of occupancy information.\n",
    "        \"\"\"\n",
    "\n",
    "        n_vehicles_per_hour = self._predict_occupancy(len(date_lst))\n",
    "        simulated_occupancy={}\n",
    "        hour= 0\n",
    "        local_tz = pytz.timezone('Europe/Madrid')\n",
    "        date_index= 0\n",
    "        \n",
    "        for n_vehicles in n_vehicles_per_hour: \n",
    "            current_date = date_lst[date_index]\n",
    "            date_hour = dt.combine(current_date, datetime.time(hour, 0)) \n",
    "            date_hour = local_tz.localize(date_hour)  # Localizarlo en la zona horaria de Madrid\n",
    "\n",
    "            if hour in self._gmm_models:\n",
    "                gm = self._gmm_models[hour]      \n",
    "                new_samples, _ = gm.sample(n_samples=n_vehicles)\n",
    "                simulated_occupancy[date_hour.strftime(\"%Y-%m-%d %H:%M\")]=[math.floor(x[0]) for x in new_samples]\n",
    "            hour = (hour+1) % 24\n",
    "            if hour == 0:\n",
    "                date_index += 1    \n",
    "        return simulated_occupancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbientModule:\n",
    "    \n",
    "    def __init__(self, lat, lon):\n",
    "        self.lat= lat\n",
    "        self.lon= lon\n",
    "\n",
    "    def train_ambient_temperature_model(self, start_date:datetime.datetime, end_date:datetime.datetime, lr=0.9, show_details=False, refresh_model=False):\n",
    "        \"\"\"\n",
    "        Trains a LSTM model using the combined temperature data.\n",
    "\n",
    "        :param combined_temp_data: DataFrame containing combined temperature data\n",
    "        \"\"\"\n",
    "        print(\"El tipo 5 es \", type(start_date), type(end_date))\n",
    "\n",
    "        ambient_temperaure_df= self._fetch_historical_temperature(start_date, end_date)\n",
    "        model_path = os.path.join('_models', 'cabintemp_lstm_model.keras')\n",
    "\n",
    "        # Normalización de los datos\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "        data = ambient_temperaure_df.copy()\n",
    "        data[\"temperature_2m\"] = scaler.fit_transform(ambient_temperaure_df[\"temperature_2m\"].values.reshape(-1, 1))\n",
    "\n",
    "        look_back = 12  # Número de pasos anteriores a considerar\n",
    "        X, y = ClimaticPark.create_sequences(data.values, look_back)\n",
    "\n",
    "        # Dividimos en entrenamiento y prueba\n",
    "        train_size = int(len(X) * lr)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "        # Redimensionamos las entradas para LSTM [samples, time steps, features]\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "        self._last_sequence = X_test[-1].flatten() \n",
    "        \n",
    "        model = None\n",
    "        # Cargamos o entrenamos el modelo\n",
    "        if os.path.exists(model_path) and not refresh_model:\n",
    "            print(f\"\\n\\tLoading ambient temperature predictor from {model_path}...\", end=\"\")\n",
    "            model = load_model(model_path)\n",
    "            print(\"DONE!\")\n",
    "        else:\n",
    "            print(f\"\\n\\tTraining and saving model in {model_path}...\")\n",
    "\n",
    "            _verbose= 0\n",
    "            if show_details:\n",
    "              _verbose= 1\n",
    "            # Configuración de EarlyStopping\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\",  # Métrica que se monitorea\n",
    "                patience=10,         # Número de épocas de espera sin mejoras antes de detener\n",
    "                restore_best_weights=True,  # Restaurar los mejores pesos\n",
    "                verbose=_verbose           # Mostrar mensajes\n",
    "            )\n",
    "\n",
    "\n",
    "            # LSTM model composition\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "            # EarlyStopping training\n",
    "            model.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                epochs=1000,\n",
    "                batch_size=16,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[early_stopping], \n",
    "                verbose=1\n",
    "            )\n",
    "            self._last_sequence = X_test[-1].flatten() \n",
    "\n",
    "        model.save(model_path)\n",
    "\n",
    "        self._model= model\n",
    "        self._scaler= scaler\n",
    "\n",
    "    def predict_ambient_temperature(self, days_lst:list):\n",
    "\n",
    "        future_predictions = {}\n",
    "        current_sequence = self._last_sequence.copy()\n",
    "\n",
    "        local_tz = pytz.timezone('Europe/Madrid')\n",
    "\n",
    "        for current_date in days_lst:\n",
    "            for hour in range(0,24):\n",
    "                date_hour = dt.combine(current_date, datetime.time(hour, 0)) \n",
    "                date_hour = local_tz.localize(date_hour)  \n",
    "\n",
    "                date_hour_str= date_hour.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "                # Redimensionar la secuencia actual para que sea compatible con el modelo\n",
    "                input_data = np.array(current_sequence).reshape((1, len(current_sequence), 1))\n",
    "                \n",
    "                # Predecir el siguiente valor\n",
    "                next_pred = self._model.predict(input_data, verbose=0)\n",
    "                \n",
    "                # Guardar el valor predicho (desnormalizado)\n",
    "                future_predictions[date_hour_str]=self._scaler.inverse_transform([[next_pred[0][0]]])[0][0]\n",
    "\n",
    "                # Actualizar la secuencia de entrada con la nueva predicción\n",
    "                current_sequence = np.append(current_sequence[1:], next_pred)\n",
    "\n",
    "        return future_predictions\n",
    "\n",
    "    # Función para obtener datos horarios históricos de Open-Meteo API\n",
    "    def _fetch_historical_temperature(self, start_date:datetime.datetime, end_date:datetime.datetime):\n",
    "          \n",
    "\n",
    "          \"\"\"\n",
    "          Obtiene datos horarios históricos de Open-Meteo API.\n",
    "\n",
    "          Args:\n",
    "          - latitude (float): Latitud de la ubicación.\n",
    "          - longitude (float): Longitud de la ubicación.\n",
    "          - start_date (str): Fecha de inicio en formato YYYY-MM-DD.\n",
    "          - end_date (str): Fecha de fin en formato YYYY-MM-DD.\n",
    "          - parameters (list): Variables meteorológicas a consultar, ej. ['temperature_2m', 'humidity_2m'].\n",
    "\n",
    "          Returns:\n",
    "          - pd.DataFrame: Datos meteorológicos horarios como DataFrame.\n",
    "          \"\"\"\n",
    "          base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "\n",
    "          # Request's payload\n",
    "          payload = {\n",
    "              \"latitude\": self.lat,\n",
    "              \"longitude\": self.lon,\n",
    "              \"start_date\": start_date,\n",
    "              \"end_date\": end_date,\n",
    "              \"hourly\": 'temperature_2m',\n",
    "              \"timezone\": \"auto\"\n",
    "          }\n",
    "\n",
    "          # API's get call\n",
    "          response = requests.get(base_url, params=payload)\n",
    "\n",
    "          if response.status_code == 200:\n",
    "              # Convertir la respuesta JSON a un DataFrame\n",
    "              data = response.json()\n",
    "              if \"hourly\" in data:\n",
    "                  df = pd.DataFrame(data[\"hourly\"])\n",
    "                  df['time'] = pd.to_datetime(df['time'])\n",
    "                  df= df.set_index('time')\n",
    "                  return df\n",
    "              else:\n",
    "                  print(\"No se encontraron datos en la respuesta.\")\n",
    "                  return pd.DataFrame()\n",
    "          else:\n",
    "              print(f\"Error en la solicitud: {response.status_code} - {response.text}\")\n",
    "              return pd.DataFrame()\n",
    "          \n",
    "    \"\"\"\n",
    "    def _forecast_uncovered_cabin_temperatures(self, ambient_temp):\n",
    "        ambient_temp_scaled = self.temp_scaler.fit_transform(ambient_temp)\n",
    "        y_pred = self.cabin_temp_model.predict(ambient_temp_scaled)\n",
    "        y_pred_rescaled = self.cabin_temp_scaler.inverse_transform(y_pred)\n",
    "        return y_pred_rescaled\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    def __init__(self,\n",
    "                 vehicle_id, \n",
    "                 entry_timestamp, \n",
    "                 exit_timestamp, \n",
    "                 assigned_space_id, \n",
    "                 initial_cabin_temp=25, \n",
    "                 target_cabin_temp= 23,\n",
    "                 coolingPower=5000,\n",
    "                 cabinVolume=3, \n",
    "                 airDensity=1.2, \n",
    "                 specificHeatAir=1005):\n",
    "        \n",
    "        self.vehicle_id = vehicle_id\n",
    "        self.entry_timestamp = entry_timestamp\n",
    "        self.exit_timestamp = exit_timestamp\n",
    "        self.assigned_space_id = assigned_space_id\n",
    "        self.initial_cabin_temp= initial_cabin_temp #celsius\n",
    "        self.final_cabin_temp= initial_cabin_temp\n",
    "        self.target_cabin_temp = target_cabin_temp\n",
    "        self.coolingPower = coolingPower\n",
    "        self.cabinVolume = cabinVolume\n",
    "        self.airDensity = airDensity\n",
    "        self.specificHeatAir = specificHeatAir\n",
    "\n",
    "    def compute_energy_consumption(self):\n",
    "        solution = self._simulate_cooling()\n",
    "        self.cooling_time = solution.t_events[0][0] if solution.t_events[0].size > 0 else solution.t[-1]\n",
    "        self.fuel_consumption = self._fuel_consumption(self.cooling_time)\n",
    "\n",
    "    def _cooling_dynamics(self, t, T_cabin):\n",
    "        dTdt = -self.coolingPower / (self.airDensity * self.cabinVolume * self.specificHeatAir)\n",
    "        return dTdt\n",
    "\n",
    "    def _target_temperature_reached(self, t, T_cabin:list):\n",
    "        return T_cabin[0] - self.target_cabin_temp\n",
    "    \n",
    "    _target_temperature_reached.terminal = True  # Event attribute\n",
    "\n",
    "    def _simulate_cooling(self, max_time=3600):\n",
    "        # As `solve_ivp` requires the event function to be independent, we define a wrapper\n",
    "        def event(t, T_cabin): return self._target_temperature_reached(t, T_cabin)\n",
    "        event.terminal = True\n",
    "\n",
    "        solution = solve_ivp(\n",
    "            self._cooling_dynamics, [0, max_time], [self.final_cabin_temp],\n",
    "            events=event, dense_output=True\n",
    "        )\n",
    "        return solution\n",
    "\n",
    "    def _fuel_consumption(self, cooling_time:float):\n",
    "        # Convert energy in joules to liters (assuming 1 liter = 3.6e6 J)\n",
    "        return (self.coolingPower * cooling_time) / 3.6e6\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {'Vehicle id.': int(self.vehicle_id), \"Entry\": self.entry_timestamp.strftime('%Y-%m-%d %H:%M'), \"Exit\": self.exit_timestamp.strftime('%Y-%m-%d %H:%M'), \"Space Id.\": int(self.assigned_space_id)}\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Vehicle({self.vehicle_id}, entry:{self.entry_timestamp.strftime('%Y-%m-%d %H:%M')}, exit:{self.exit_timestamp.strftime('%Y-%m-%d %H:%M')}, space:{self.assigned_space_id}, init_temp:{self.initial_cabin_temp}, final_temp:{self.final_cabin_temp})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "class OccupancyModule:\n",
    "\n",
    "    def __init__(self, spaces:gpd.GeoDataFrame, gates:gpd.GeoDataFrame):\n",
    "        self._spaces= spaces\n",
    "        self._gates= gates\n",
    "        \n",
    "        self._spaces[['nearest_gate_id', 'nearest_gate_dist']] = self._spaces.geometry.apply(lambda poly: self._nearest_point(poly))\n",
    "        \n",
    "    def _nearest_point(self, polygon:Polygon):\n",
    "        distances = self._gates.geometry.distance(polygon)\n",
    "        nearest_idx = distances.idxmin()\n",
    "        return pd.Series([self._gates.loc[nearest_idx, 'id'], distances[nearest_idx]])\n",
    "    \n",
    "    def _select_weighted_random_row(self, gdf:gpd.GeoDataFrame, weight_col='nearest_gate_dist'):\n",
    "\n",
    "        try:\n",
    "            if weight_col not in gdf.columns:\n",
    "                raise ValueError(f\"Column {weight_col} does not exist in GeoDataFrame\")\n",
    "            \n",
    "            weights = gdf[weight_col].values\n",
    "\n",
    "            max_finite = np.nanmax(weights[weights != np.inf])  # Máximo valor finito en p\n",
    "            if np.isfinite(max_finite):\n",
    "                weights = np.where(np.isinf(weights), max_finite, weights)  # Reemplazar inf por el máximo finito\n",
    "            \n",
    "            min_finite = np.nanmin(weights[weights != 0])  # Máximo valor finito en p\n",
    "\n",
    "            weights = weights + min_finite\n",
    "            inv_weights = 1 / weights    \n",
    "            norm_inv_weights = inv_weights / np.sum(inv_weights)\n",
    "            selected_idx = np.random.choice(gdf.index, p=norm_inv_weights)\n",
    "            return selected_idx\n",
    "        except:\n",
    "            print(\"WARN: It was not possible to assign space to incoming vehicle\")\n",
    "            return -1\n",
    "\n",
    "    def simulate_occupancies(self, days_lst:list, entry_exits:dict):\n",
    "\n",
    "        local_tz = pytz.timezone('Europe/Madrid')\n",
    "\n",
    "        simulated_occupancy = self._spaces.copy()\n",
    "\n",
    "        last_column_name = None\n",
    "        occupied_spaces_dict = {}\n",
    "        vehicles_dict= {}\n",
    "        current_vehicle_id = 0\n",
    "        for current_date in days_lst:\n",
    "            for entry_hour in range(0,24):\n",
    "                \n",
    "                date_hour = dt.combine(current_date, datetime.time(entry_hour, 0)) \n",
    "                date_hour = local_tz.localize(date_hour)  \n",
    "\n",
    "                date_hour_str= date_hour.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "                current_column_name= f'occupancy_{date_hour_str}'\n",
    "\n",
    "                if last_column_name is not None:\n",
    "                    simulated_occupancy[current_column_name]= simulated_occupancy[last_column_name]\n",
    "                else:\n",
    "                    simulated_occupancy[current_column_name]= -1 #False\n",
    "\n",
    "                new_vacant_spaces_lst= []\n",
    "                if date_hour_str in occupied_spaces_dict:\n",
    "                    new_vacant_spaces_lst= occupied_spaces_dict[date_hour_str]\n",
    "                \n",
    "                for vacant_space in new_vacant_spaces_lst:\n",
    "                    simulated_occupancy.at[vacant_space,current_column_name]= -1 #False\n",
    "\n",
    "                if date_hour_str in entry_exits:\n",
    "                    exit_hours_lst = entry_exits[date_hour_str]\n",
    "                    for exit_hour in exit_hours_lst:\n",
    "                        selected_space = self._select_weighted_random_row(simulated_occupancy[simulated_occupancy[current_column_name]==-1])\n",
    "                        if selected_space >= 0:\n",
    "\n",
    "                            simulated_occupancy.at[selected_space,current_column_name]= current_vehicle_id#True\n",
    "\n",
    "                            if exit_hour > entry_hour:\n",
    "                                date_exit_hour = dt.combine(current_date, datetime.time(exit_hour, 0)) \n",
    "                            elif exit_hour == entry_hour:\n",
    "                                date_exit_hour = dt.combine(current_date, datetime.time((exit_hour+1)%24, 0)) \n",
    "                            else:\n",
    "                                next_date= current_date + timedelta(days=1)\n",
    "                                date_exit_hour = dt.combine(next_date, datetime.time(exit_hour, 0)) \n",
    "\n",
    "                            date_exit_hour = local_tz.localize(date_exit_hour)  \n",
    "                            date_exit_hour_str= date_exit_hour.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "                            vehicle = Vehicle(current_vehicle_id, date_hour, date_exit_hour, selected_space)\n",
    "                            vehicles_dict[current_vehicle_id]= vehicle\n",
    "                            current_vehicle_id += 1\n",
    "\n",
    "                            exit_hour_spaces = occupied_spaces_dict.get(date_exit_hour_str,[])\n",
    "                            exit_hour_spaces.append(selected_space)\n",
    "                            occupied_spaces_dict[date_exit_hour_str]= exit_hour_spaces\n",
    "\n",
    "                last_column_name= current_column_name\n",
    "        self._simulated_occupancy = simulated_occupancy\n",
    "        self._vehicles_dict= vehicles_dict\n",
    "\n",
    "        return simulated_occupancy, vehicles_dict\n",
    "    \n",
    "    def show_occupancy_map(self):\n",
    "        # Extraer las columnas de tiempo (asegurarse de que están ordenadas)\n",
    "        occupancy_cols = [col for col in self._simulated_occupancy.columns if \"occupancy_\" in col]\n",
    "        occupancy_cols.sort()\n",
    "\n",
    "        # Crear el mapa base centrado en el área de los polígonos\n",
    "        m = folium.Map(\n",
    "            location=[self._simulated_occupancy.geometry.centroid.y.mean(), self._simulated_occupancy.geometry.centroid.x.mean()],\n",
    "            zoom_start=16,\n",
    "            max_zoom= 19,\n",
    "            tiles=\"cartodb positron\"\n",
    "        )\n",
    "\n",
    "        def get_color(cell_value):\n",
    "            if cell_value >= 0:\n",
    "                return \"#FF0000\"\n",
    "            return  \"#CCCCCC\"\n",
    "        \n",
    "        def get_popup_value(cell_value):\n",
    "            if cell_value in self._vehicles_dict:\n",
    "                return str(self._vehicles_dict[cell_value].to_dict())\n",
    "            return \"Empty\"\n",
    "\n",
    "        # Crear una estructura para `TimestampedGeoJson`\n",
    "        features = []\n",
    "\n",
    "        for index, row in self._simulated_occupancy.iterrows():\n",
    "            for time_index, col in enumerate(occupancy_cols):\n",
    "                feature = {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": mapping(row.geometry),  # Convertir a JSON\n",
    "                    \"properties\": {\n",
    "                        \"time\": col.replace(\"occupancy_\", \"\"),  # Extraer la fecha y hora\n",
    "                        \"style\": {\n",
    "                            \"fillColor\": get_color(row[col]),\n",
    "                            \"color\": \"black\",\n",
    "                            \"weight\": 0.5,\n",
    "                            \"fillOpacity\": 0.7,\n",
    "                        },\n",
    "                        \"popup\": get_popup_value(row[col])  #f\"Occupied: {row[col]}\"\n",
    "                    }\n",
    "                }\n",
    "                features.append(feature)\n",
    "        # Crear un `TimestampedGeoJson`\n",
    "        TimestampedGeoJson(\n",
    "            {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": features,\n",
    "            },\n",
    "            period=\"PT1H\",  # Intervalo de tiempo (1 hora)\n",
    "            duration= \"PT1H\",\n",
    "            add_last_point=False,\n",
    "            auto_play=False,\n",
    "            loop=True,\n",
    "            max_speed=1,\n",
    "            loop_button=True,\n",
    "            date_options=\"YYYY-MM-DD HH:mm\",\n",
    "        ).add_to(m)\n",
    "        \n",
    "        folium.LayerControl().add_to(m)\n",
    "\n",
    "        # Guardar el mapa como HTML\n",
    "        m.save(\".climaticpark_occupancy_map.html\")\n",
    "\n",
    "        return m        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CabinTemperatureModule:\n",
    "\n",
    "    def __init__(self, data_no_roof:pd.DataFrame, data_roof:pd.DataFrame):\n",
    "        \n",
    "        self._data_no_roof= data_no_roof\n",
    "        self._data_roof= data_roof\n",
    "        self._temp_data = pd.concat([self._data_no_roof, self._data_roof], axis=0)\n",
    "\n",
    "        X= self._temp_data['T temp_ext coverage'.split()].values\n",
    "        y= self._temp_data['temp_int'].values\n",
    "\n",
    "        self._cabin_temp_pred = LinearRegression().fit(X, y)\n",
    "\n",
    "    def simulate_cabin_temperatures(self, vehicles_dict:dict, coverage_rates_gdf:gpd.GeoDataFrame, forecasted_ambient_temp_dict:dict):\n",
    "\n",
    "        self._cabin_temp_gdf= coverage_rates_gdf.copy()\n",
    "        self._cabin_temp_gdf= self._cabin_temp_gdf.drop(columns='height nearest_gate_id nearest_gate_dist'.split())\n",
    "        self._cabin_temp_gdf.columns= [c.replace('coverage_rate_', 'cabin_temp_') for c in self._cabin_temp_gdf.columns]\n",
    "\n",
    "        for c in self._cabin_temp_gdf.columns:\n",
    "            if c.startswith('cabin_temp_'):\n",
    "                self._cabin_temp_gdf[c]= '-'\n",
    "    \n",
    "        for vehicle_id, vehicle in vehicles_dict.items():\n",
    "            space_id= vehicle.assigned_space_id\n",
    "            entry_date = vehicle.entry_timestamp\n",
    "            current_date = vehicle.entry_timestamp\n",
    "            date_lst= []\n",
    "            while current_date <= vehicle.exit_timestamp:\n",
    "                date_lst.append(current_date)\n",
    "                current_date += timedelta(hours=1)\n",
    "\n",
    "            for i in range(len(date_lst)):\n",
    "                d = date_lst[i]\n",
    "                d_str= d.strftime(\"%Y-%m-%d %H:%M\")\n",
    "                amb_temp= forecasted_ambient_temp_dict[d_str]\n",
    "                coverage_rate = coverage_rates_gdf.at[space_id, f'coverage_rate_{d_str}']\n",
    "                \n",
    "                cabin_temp = self._cabin_temp_pred.predict(np.array([i+1,amb_temp,coverage_rate]).reshape(1,-1))\n",
    "                \n",
    "                self._cabin_temp_gdf.at[space_id, f'cabin_temp_{d_str}']= cabin_temp[0]\n",
    "\n",
    "            vehicle.final_cabin_temp= cabin_temp[0]\n",
    "        return vehicles_dict\n",
    "    \n",
    "    def show_cabintemp_map(self):\n",
    "\n",
    "        cabintemp_cols = [col for col in self._cabin_temp_gdf.columns if \"cabin_temp_\" in col]\n",
    "        cabintemp_cols.sort()\n",
    "\n",
    "        m = folium.Map(\n",
    "            location=[self._cabin_temp_gdf.geometry.centroid.y.mean(), self._cabin_temp_gdf.geometry.centroid.x.mean()],\n",
    "            zoom_start=16,\n",
    "            max_zoom= 19,\n",
    "            tiles=\"cartodb positron\"\n",
    "        )\n",
    "\n",
    "        colormap = branca.colormap.linear.YlOrRd_04.scale(\n",
    "            self._cabin_temp_gdf.replace('-', np.nan)[cabintemp_cols].min().min(), self._cabin_temp_gdf.replace('-', np.nan)[cabintemp_cols].max().max()\n",
    "        )\n",
    "        colormap.caption = \"Coverage Rate\"\n",
    "        colormap.add_to(m)\n",
    "\n",
    "        # Crear una estructura para `TimestampedGeoJson`\n",
    "        features = []\n",
    "\n",
    "        for index, row in self._cabin_temp_gdf.iterrows():\n",
    "            for time_index, col in enumerate(cabintemp_cols):\n",
    "                \n",
    "                feature = {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": mapping(row.geometry),  # Convertir a JSON\n",
    "                    \"properties\": {\n",
    "                        \"time\": col.replace(\"cabin_temp_\", \"\"),  # Extraer la fecha y hora\n",
    "                        \"style\": {\n",
    "                            \"fillColor\": colormap(row[col]) if row[col] != '-' else colormap(0),  # Color según la cobertura\n",
    "                            \"color\": \"black\",\n",
    "                            \"weight\": 0.5,\n",
    "                            \"fillOpacity\": 0.7,\n",
    "                        },\n",
    "                        \"popup\": f\"Cabin temp:{row[col]:.2f} Cº\" if row[col] != '-' else '-'\n",
    "                    }\n",
    "                }\n",
    "                features.append(feature)\n",
    "\n",
    "        # Crear un `TimestampedGeoJson`\n",
    "        TimestampedGeoJson(\n",
    "            {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": features,\n",
    "            },\n",
    "            period=\"PT1H\",  # Intervalo de tiempo (1 hora)\n",
    "            duration= \"PT1H\",\n",
    "            add_last_point=False,\n",
    "            auto_play=False,\n",
    "            loop=True,\n",
    "            max_speed=1,\n",
    "            loop_button=True,\n",
    "            date_options=\"YYYY-MM-DD HH:mm\",\n",
    "        ).add_to(m)\n",
    "        \n",
    "        folium.LayerControl().add_to(m)\n",
    "\n",
    "        # Guardar el mapa como HTML\n",
    "        m.save(\".climaticpark_cabintemp_map.html\")\n",
    "\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClimaticParkState(Enum):\n",
    "    INIT = 1\n",
    "    READY = 2\n",
    "    LAUNCHED = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3haCJlsN8hF"
   },
   "outputs": [],
   "source": [
    "class ClimaticPark:\n",
    "    def __init__(self, file_name_lots='data/parking_lots.geojson',\n",
    "                 file_name_roofs='data/parking_roofs.geojson',\n",
    "                 file_name_coords='data/parking_coordinates.csv',\n",
    "                 file_name_gates='data/gates_coordinates.csv',\n",
    "                 file_name_cabintem='data/historical_cabin_temp.csv'):\n",
    "        \"\"\"\n",
    "        Initializes the ClimaticPark object by loading all necessary files.\n",
    "        \"\"\"\n",
    "        # Load GeoJSON files for lots and roofs\n",
    "        self.lots_data = ClimaticPark.load_geojson(file_name_lots)\n",
    "        self.lots_data['space_id']= list(range(len(self.lots_data )))\n",
    "        self.roofs_data = ClimaticPark.load_geojson(file_name_roofs)\n",
    "\n",
    "        # Add 'height' column to roofs_data with a value of 1 for all rows\n",
    "        if (self.lots_data is not None) and ('height' not in self.lots_data.columns):\n",
    "            self.lots_data['height'] = 0 # Assuming a default height of 1\n",
    "\n",
    "        # Add 'height' column to roofs_data with a value of 1 for all rows\n",
    "        if (self.roofs_data is not None) and ('height' not in self.roofs_data.columns):\n",
    "            self.roofs_data['height'] = 2  # Assuming a default height of 1\n",
    "\n",
    "        # Load CSV files for coordinates, historical data, and additional data\n",
    "        self.coords_data = ClimaticPark.load_csv(file_name_coords)\n",
    "        self.gates_data = ClimaticPark.load_csv(file_name_gates)\n",
    "\n",
    "        # Convertir en un GeoDataFrame\n",
    "        self.gates_data = gpd.GeoDataFrame(self.gates_data, geometry=gpd.points_from_xy(self.gates_data.longitude, \n",
    "                                                                                        self.gates_data.latitude), \n",
    "                                                                                        crs=\"EPSG:4326\")  # WGS 84\n",
    "        self.gates_data['id']= self.gates_data.index\n",
    "      \n",
    "        data_no_roof =  ClimaticPark.load_csv(os.path.join('data', 'cabin_temperature_no_roof.csv'))\n",
    "        data_no_roof['coverage']=0\n",
    "        data_roof =  ClimaticPark.load_csv(os.path.join('data', 'cabin_temperature_w_roof.csv'))\n",
    "        data_roof['coverage']=1\n",
    "\n",
    "        self.recorded_cabin_temp = pd.read_csv(file_name_cabintem, index_col=0)\n",
    "        # Convertir la columna DateTime a tipo datetime\n",
    "        self.recorded_cabin_temp['DateTime'] = pd.to_datetime(self.recorded_cabin_temp['DateTime'])\n",
    "        # Establecer la columna DateTime como índice\n",
    "        self.recorded_cabin_temp.set_index('DateTime', inplace=True)\n",
    "        # Remuestrear los datos para obtener una frecuencia de 1 hora (calculando la media)\n",
    "        self.recorded_cabin_temp = self.recorded_cabin_temp.resample('h').mean()\n",
    "\n",
    "        self.entry_exit_tuples= pd.read_csv(os.path.join('data', 'entry_exit_tuples_clean.csv'), index_col=0, dtype={'id_subject':str}, parse_dates=['date'])\n",
    "        \n",
    "        os.makedirs('_models', exist_ok=True)\n",
    "        self.cabin_temp_model = None\n",
    "        self.cabin_coverage_model= None\n",
    "        print(\"Generating Demand Module...\", end=\"\")\n",
    "        self.demand_module = DemandModule(self.entry_exit_tuples)\n",
    "        print(\"DONE!\")\n",
    "\n",
    "        print(\"Generating Ocupancy Module...\", end=\"\")\n",
    "        self.occupancy_module = OccupancyModule(self.lots_data, self.gates_data)\n",
    "        print(\"DONE!\")\n",
    "        \n",
    "        lat = self.coords_data['latitude'].iloc[0]  \n",
    "        lon = self.coords_data['longitude'].iloc[0]\n",
    "        \n",
    "        print(\"Generating Shadow Module...\", end=\"\")\n",
    "        self.shadow_module = ShadowModule(self.roofs_data, self.lots_data)\n",
    "        print(\"DONE!\")\n",
    "\n",
    "        print(\"Generating Ambient Module...\", end=\"\")\n",
    "        self.ambient_module = AmbientModule(lat,lon)\n",
    "        print(\"DONE!\")\n",
    "\n",
    "        print(\"Generating Cabin Temperature Module...\", end=\"\")\n",
    "        self.cabin_module = CabinTemperatureModule(data_no_roof, data_roof)\n",
    "        print(\"DONE!\")\n",
    "\n",
    "        self._state = ClimaticParkState.INIT\n",
    "\n",
    "    @staticmethod\n",
    "    def load_geojson(file_name:str):\n",
    "        \"\"\"\n",
    "        Loads a GeoJSON file into a GeoDataFrame.\n",
    "        \"\"\"\n",
    "        if file_name:\n",
    "            return gpd.read_file(file_name).set_geometry(\"geometry\")\n",
    "        else:\n",
    "            print(f\"No GeoJSON file provided for {file_name}.\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_csv(file_name:str):\n",
    "        \"\"\"\n",
    "        Loads a CSV file into a DataFrame.\n",
    "        \"\"\"\n",
    "        if file_name:\n",
    "            return pd.read_csv(file_name)\n",
    "        else:\n",
    "            print(f\"No CSV file provided for {file_name}.\")\n",
    "            return None\n",
    "\n",
    "    def prepare_simulation(self, lr=0.8, display_details=False):\n",
    "        print(\"Preparing simulation for TPL...\")\n",
    "\n",
    "        init_date =  self.recorded_cabin_temp.index[0].date()\n",
    "        final_date =  self.recorded_cabin_temp.index[-1].date()\n",
    "\n",
    "        # Process temperature data\n",
    "        print(\"\\tTraining ambient temperature predictors...\",end=\"\")\n",
    "        self.ambient_module.train_ambient_temperature_model(init_date, final_date)\n",
    "        #combined_temp_df= pd.concat([ambient_temp_df, self.recorded_cabin_temp], axis=1)\n",
    "        #combined_temp_df = combined_temp_df.dropna()\n",
    "\n",
    "\n",
    "        #print(\"Training cabin temperature predictors...\",end=\"\")\n",
    "        #self.cabin_temp_model, self.temp_scaler, self.cabin_temp_scaler = self._train_cabin_temperature_model(combined_temp_df, lr, display_details)\n",
    "        #self.cabin_coverage_model= self._train_cabin_temperature_and_coverage_model()\n",
    "        #print(\"DONE!\")\n",
    "\n",
    "        print(\"\\tTraining demand predictors...\",end=\"\")\n",
    "        self.demand_module.train_demand_predictors()  \n",
    "\n",
    "        self._state = ClimaticParkState.READY\n",
    "\n",
    "        print(\"Simulation ready to go!!\")\n",
    "\n",
    "    def launch_simulation(self, n_days_ahead:int, display_details=True):\n",
    "        \"\"\"\n",
    "        Lauch simulation for n_days_ahead \n",
    "        \"\"\"\n",
    "        print(\"Starting simulation of TPL...\")\n",
    "\n",
    "        \n",
    "        init_day = self.entry_exit_tuples['date'].max()\n",
    "        \n",
    "        madrid_tz = pytz.timezone(\"Europe/Madrid\")\n",
    "        init_day = madrid_tz.localize(init_day)\n",
    "\n",
    "        date_lst = [init_day + timedelta(days=i) for i in range(n_days_ahead)]\n",
    "        entry_exits= self.demand_module.generate_entry_exit_hours(date_lst)\n",
    "\n",
    "        simulated_occupancy, simulated_vehicles_dict = self.occupancy_module.simulate_occupancies(date_lst, entry_exits)    \n",
    "        simulated_coverage_rates= self.shadow_module.compute_coverage_rates(date_lst)\n",
    "\n",
    "        forecasted_ambient_temp_dict= self.ambient_module.predict_ambient_temperature(date_lst)\n",
    "\n",
    "        self.vehicles_dict = self.cabin_module.simulate_cabin_temperatures(simulated_vehicles_dict, simulated_coverage_rates, forecasted_ambient_temp_dict)\n",
    " \n",
    "        \n",
    "        self._state = ClimaticParkState.LAUNCHED\n",
    "        print(\"Simulation launched. You can get access to the simulation data.\")\n",
    "\n",
    "\n",
    "    def show_coverage_rates(self):\n",
    "        if self._state == ClimaticParkState.LAUNCHED:\n",
    "            return self.shadow_module.show_coverage_rate_map()\n",
    "        else:\n",
    "            print(\"You must first launch the simulation by calling the launch_simulation method.\")\n",
    "    \n",
    "    def show_roofs_projected_shadows(self):\n",
    "        if self._state == ClimaticParkState.LAUNCHED:\n",
    "            return self.shadow_module.show_shadow_map()\n",
    "        else:\n",
    "            print(\"You must first launch the simulation by calling the launch_simulation method.\")\n",
    "\n",
    "    def show_occupancy(self):\n",
    "        if self._state == ClimaticParkState.LAUNCHED:\n",
    "            return self.occupancy_module.show_occupancy_map()\n",
    "        else:\n",
    "            print(\"You must first launch the simulation by calling the launch_simulation method.\")\n",
    "\n",
    "    def show_cabin_temps(self):\n",
    "        if self._state == ClimaticParkState.LAUNCHED:\n",
    "            return self.cabin_module.show_cabintemp_map()\n",
    "        else:\n",
    "            print(\"You must first launch the simulation by calling the launch_simulation method.\")\n",
    "\n",
    "    def compute_energy_consumption(self):\n",
    "\n",
    "        if self._state == ClimaticParkState.LAUNCHED:\n",
    "            vehicle_lst = []\n",
    "            for v_id, v in self.vehicles_dict.items():\n",
    "                v.compute_energy_consumption()\n",
    "                vehicle_lst.append(v.__dict__)\n",
    "            \n",
    "            vehicles_df = pd.DataFrame(vehicle_lst)#.from_dict(self.vehicles_dict, orient='index')\n",
    "            print(vehicles_df)\n",
    "        else:\n",
    "            print(\"You must first launch the simulation by calling the launch_simulation method.\")\n",
    "        \n",
    "   \n",
    "\n",
    "    # Preparamos el dataset para secuencias\n",
    "    @staticmethod\n",
    "    def create_sequences(data, look_back:int):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - look_back):\n",
    "            X.append(data[i:i + look_back])  # Secuencias de la variable 'a'\n",
    "            y.append(data[i + look_back])  # Predicción futura de la variable 'b'\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "okbjHghGOYix",
    "outputId": "c4f6263c-ddf9-4dfa-d05f-59486896d7c6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "park = ClimaticPark() # default parameters\n",
    "park.prepare_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.launch_simulation(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= park.show_coverage_rates()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= park.show_roofs_projected_shadows()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= park.show_occupancy()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= park.show_cabin_temps()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_consumption_df = park.compute_energy_consumption()\n",
    "print(vehicle_consumption_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That's all folks!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "climaticpark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
